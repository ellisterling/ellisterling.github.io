[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  },
  {
    "objectID": "posts/Penguins/index.html",
    "href": "posts/Penguins/index.html",
    "title": "Classifying Palmer Penguins",
    "section": "",
    "text": "Abstract\nIn this blog post, we will analyze the Palmer Penguins dataset, which was collected by Dr. Kristen Gorman and the Palmer Station in Antarctica. It contains various types of quantitative and qualitative data about the penguins observed by Gorman et al. To analyze this data, we will train a machine learning model on it, and find the best combination of features to train that model on. We will then test our model against the test dataset and determine its usability. The model we will use is a Logistic Regression model, which uses linear equations to create boundaries and categorizes based on those boundaries.\n\n\nSetup\nFirst we can load in the data as a Pandas dataframe.\n\nimport pandas as pd\nimport numpy as np\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\n\ntrain_url = \"https://raw.githubusercontent.com/PhilChodrow/ml-notes/main/data/palmer-penguins/train.csv\"\ntrain = pd.read_csv(train_url)\n\nWe can then look at the dataframe we have made:\n\ntrain.head()\n\n\n\n\n\n\n\n\nstudyName\nSample Number\nSpecies\nRegion\nIsland\nStage\nIndividual ID\nClutch Completion\nDate Egg\nCulmen Length (mm)\nCulmen Depth (mm)\nFlipper Length (mm)\nBody Mass (g)\nSex\nDelta 15 N (o/oo)\nDelta 13 C (o/oo)\nComments\n\n\n\n\n0\nPAL0809\n31\nChinstrap penguin (Pygoscelis antarctica)\nAnvers\nDream\nAdult, 1 Egg Stage\nN63A1\nYes\n11/24/08\n40.9\n16.6\n187.0\n3200.0\nFEMALE\n9.08458\n-24.54903\nNaN\n\n\n1\nPAL0809\n41\nChinstrap penguin (Pygoscelis antarctica)\nAnvers\nDream\nAdult, 1 Egg Stage\nN74A1\nYes\n11/24/08\n49.0\n19.5\n210.0\n3950.0\nMALE\n9.53262\n-24.66867\nNaN\n\n\n2\nPAL0708\n4\nGentoo penguin (Pygoscelis papua)\nAnvers\nBiscoe\nAdult, 1 Egg Stage\nN32A2\nYes\n11/27/07\n50.0\n15.2\n218.0\n5700.0\nMALE\n8.25540\n-25.40075\nNaN\n\n\n3\nPAL0708\n15\nGentoo penguin (Pygoscelis papua)\nAnvers\nBiscoe\nAdult, 1 Egg Stage\nN38A1\nYes\n12/3/07\n45.8\n14.6\n210.0\n4200.0\nFEMALE\n7.79958\n-25.62618\nNaN\n\n\n4\nPAL0809\n34\nChinstrap penguin (Pygoscelis antarctica)\nAnvers\nDream\nAdult, 1 Egg Stage\nN65A2\nYes\n11/24/08\n51.0\n18.8\n203.0\n4100.0\nMALE\n9.23196\n-24.17282\nNaN\n\n\n\n\n\n\n\nWe can shorten the species of the penguins to just the first word, which will make it easier to catalogue them.\n\ntrain[\"Species\"] = train[\"Species\"].str.split().str.get(0)\ntrain.head()\n\n\n\n\n\n\n\n\nstudyName\nSample Number\nSpecies\nRegion\nIsland\nStage\nIndividual ID\nClutch Completion\nDate Egg\nCulmen Length (mm)\nCulmen Depth (mm)\nFlipper Length (mm)\nBody Mass (g)\nSex\nDelta 15 N (o/oo)\nDelta 13 C (o/oo)\nComments\n\n\n\n\n0\nPAL0809\n31\nChinstrap\nAnvers\nDream\nAdult, 1 Egg Stage\nN63A1\nYes\n11/24/08\n40.9\n16.6\n187.0\n3200.0\nFEMALE\n9.08458\n-24.54903\nNaN\n\n\n1\nPAL0809\n41\nChinstrap\nAnvers\nDream\nAdult, 1 Egg Stage\nN74A1\nYes\n11/24/08\n49.0\n19.5\n210.0\n3950.0\nMALE\n9.53262\n-24.66867\nNaN\n\n\n2\nPAL0708\n4\nGentoo\nAnvers\nBiscoe\nAdult, 1 Egg Stage\nN32A2\nYes\n11/27/07\n50.0\n15.2\n218.0\n5700.0\nMALE\n8.25540\n-25.40075\nNaN\n\n\n3\nPAL0708\n15\nGentoo\nAnvers\nBiscoe\nAdult, 1 Egg Stage\nN38A1\nYes\n12/3/07\n45.8\n14.6\n210.0\n4200.0\nFEMALE\n7.79958\n-25.62618\nNaN\n\n\n4\nPAL0809\n34\nChinstrap\nAnvers\nDream\nAdult, 1 Egg Stage\nN65A2\nYes\n11/24/08\n51.0\n18.8\n203.0\n4100.0\nMALE\n9.23196\n-24.17282\nNaN\n\n\n\n\n\n\n\n\n\nFigure Creation\nNow that we’ve preprocessed the data a little bit, we can create a few plots to get an idea of what this data means. Below, we use seaborn to create a scatterplot and a bar plot.\n\nfig, ax = plt.subplots(2, 1, figsize = (3.5, 8))\n\np1 = sns.scatterplot(train, x = \"Flipper Length (mm)\", y = 'Delta 13 C (o/oo)', hue = \"Species\", style = \"Species\", ax = ax[0])\np2 = sns.barplot(train, x = \"Island\", y = \"Body Mass (g)\", hue = 'Species')\n\n\n\n\n\n\n\n\nFigure 1: A scatterplot showing flipper length against Delta 13 C for three species of penguins. We can see that there is some correlation, but at the edges the species overlap a bit.\nFigure 2: A bar graph showing body mass for each species on each island. Torgerson only contains Adelie, Dream has pretty equal body masses for Adelie and Chinstrap, and Biscoe has Gentoo penguins at a much larger size than the other penguins.\nFrom these figures, we can tell that flipper length differentiates Adelie and Gentoo penguins, and that Delta 13 C differentiates Adelie and Chinstrap penguins. However, we do get some overlap between Chinstrap and Adelie that would reduce model accuracy. The second plot shows that only Adelie penguins were observed on Torgerson, Gentoos were only observed on Biscoe, and Chinstraps were only observed on Dream. Although Adelie penguins are found on all three islands, there is enough separation that we can assume that it would be an informative factor to include.\nNow that we’ve seen some of the data plotted out, we can continue the preprocessing step. The predict() function below drops unnecessary columns, rows/columns with null values, assigns species to integers rather than strings, and then splits the species into a separate data structure, y.\n\nfrom sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\nle.fit(train[\"Species\"])\n\ndef prepare_data(df):\n  df = df.drop([\"studyName\", \"Sample Number\", \"Individual ID\", \"Date Egg\", \"Comments\", \"Region\"], axis = 1)\n  df = df[df[\"Sex\"] != \".\"]\n  df = df.dropna()\n  y = le.transform(df[\"Species\"])\n  df = df.drop([\"Species\"], axis = 1)\n  df = pd.get_dummies(df)\n  return df, y\n\nx_train, y_train = prepare_data(train)\nx_train\n\n\n\n\n\n\n\n\nCulmen Length (mm)\nCulmen Depth (mm)\nFlipper Length (mm)\nBody Mass (g)\nDelta 15 N (o/oo)\nDelta 13 C (o/oo)\nIsland_Biscoe\nIsland_Dream\nIsland_Torgersen\nStage_Adult, 1 Egg Stage\nClutch Completion_No\nClutch Completion_Yes\nSex_FEMALE\nSex_MALE\n\n\n\n\n0\n40.9\n16.6\n187.0\n3200.0\n9.08458\n-24.54903\nFalse\nTrue\nFalse\nTrue\nFalse\nTrue\nTrue\nFalse\n\n\n1\n49.0\n19.5\n210.0\n3950.0\n9.53262\n-24.66867\nFalse\nTrue\nFalse\nTrue\nFalse\nTrue\nFalse\nTrue\n\n\n2\n50.0\n15.2\n218.0\n5700.0\n8.25540\n-25.40075\nTrue\nFalse\nFalse\nTrue\nFalse\nTrue\nFalse\nTrue\n\n\n3\n45.8\n14.6\n210.0\n4200.0\n7.79958\n-25.62618\nTrue\nFalse\nFalse\nTrue\nFalse\nTrue\nTrue\nFalse\n\n\n4\n51.0\n18.8\n203.0\n4100.0\n9.23196\n-24.17282\nFalse\nTrue\nFalse\nTrue\nFalse\nTrue\nFalse\nTrue\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n270\n51.1\n16.5\n225.0\n5250.0\n8.20660\n-26.36863\nTrue\nFalse\nFalse\nTrue\nFalse\nTrue\nFalse\nTrue\n\n\n271\n35.9\n16.6\n190.0\n3050.0\n8.47781\n-26.07821\nFalse\nFalse\nTrue\nTrue\nTrue\nFalse\nTrue\nFalse\n\n\n272\n39.5\n17.8\n188.0\n3300.0\n9.66523\n-25.06020\nFalse\nTrue\nFalse\nTrue\nFalse\nTrue\nTrue\nFalse\n\n\n273\n36.7\n19.3\n193.0\n3450.0\n8.76651\n-25.32426\nFalse\nFalse\nTrue\nTrue\nFalse\nTrue\nTrue\nFalse\n\n\n274\n42.4\n17.3\n181.0\n3600.0\n9.35138\n-24.68790\nFalse\nTrue\nFalse\nTrue\nFalse\nTrue\nTrue\nFalse\n\n\n\n\n256 rows × 14 columns\n\n\n\n\n\nDeciding on attributes\nWe now need to pick the attributes that will yield the best prediction accuracy. To do this, we will use an exhaustive approach, where we check the accuracy of a linear regression model trained on all possible feature combinations. In the code below, we loop through all possible combinations of qualitative and quantitative attributes. In each iteration, we train a model on the different combinations of features, and we compile an array of all the combinations (along with their scores and the model that was trained on them).\n\nfrom itertools import combinations\nfrom sklearn.linear_model import LogisticRegression\n\nall_qual_cols = [\"Clutch Completion\", \"Island\", \"Sex\", \"Stage\"]\nall_quant_cols = ['Culmen Length (mm)', 'Culmen Depth (mm)', 'Flipper Length (mm)', \"Body Mass (g)\", \"Delta 15 N (o/oo)\", \"Delta 13 C (o/oo)\"]\nscores = []\ncombo_array = []\n\n\nfor qual in all_qual_cols:\n  qual_cols = [col for col in x_train.columns if qual in col ]\n  for pair in combinations(all_quant_cols, 2):\n1    cols = list(pair) + qual_cols\n    combo_array.append(cols)\n2    LR = LogisticRegression()\n    LR.fit(x_train[cols], y_train)\n3    new_score = LR.score(x_train[cols], y_train)\n4    scores.append((cols, new_score, LR))\n\n\n1\n\nGather the features for this iteration\n\n2\n\nCreate the Logistic Regression model and train it on our selected features\n\n3\n\nScore the trained model\n\n4\n\nAdd the features, score, and model as a tuple to the array of our catalogued models\n\n\n\n\n\nfrom operator import itemgetter\nbest_combo = max(scores, key = itemgetter(1))\nprint(best_combo)\nbest_attrs = best_combo[0]\nbest_score = best_combo[1]\nbest_lr = best_combo[2]\n\n(['Culmen Length (mm)', 'Culmen Depth (mm)', 'Island_Biscoe', 'Island_Dream', 'Island_Torgersen'], 0.99609375, LogisticRegression())\n\n\nIt looks like Island, Culmen Length, and Culmen Depth are our most helpful attributes.\nNext, we need to prepare our test data in the same way that we prepared our training data.\n\ntest_url = \"https://raw.githubusercontent.com/PhilChodrow/ml-notes/main/data/palmer-penguins/test.csv\"\ntest = pd.read_csv(test_url)\ntest[\"Species\"] = test[\"Species\"].str.split().str.get(0)\nx_test, y_test = prepare_data(test)\n\nWe can then score our trained model on its performance with the test data.\n\nbest_lr.score(x_test[best_attrs], y_test)\n\n1.0\n\n\nGreat! We have 100% accuracy on the testing data. Now for some more plotting…\n\n\nPlotting the Category Regions\nUsing Matplotlib, we can display the categories on a plot as colored regions. This allows us to visualize how the test points are categorized, and we can get a visual representation of the accuracy of the model.\n\nfrom matplotlib import pyplot as plt\nimport numpy as np\n\nfrom matplotlib.patches import Patch\n\ndef plot_regions(model, X, y):\n    \n    x0 = X[X.columns[0]]\n    x1 = X[X.columns[1]]\n    qual_features = X.columns[2:]\n    \n    fig, axarr = plt.subplots(1, len(qual_features), figsize = (7, 3))\n\n    # create a grid\n    grid_x = np.linspace(x0.min(),x0.max(),501)\n    grid_y = np.linspace(x1.min(),x1.max(),501)\n    xx, yy = np.meshgrid(grid_x, grid_y)\n    \n    XX = xx.ravel()\n    YY = yy.ravel()\n\n    for i in range(len(qual_features)):\n      XY = pd.DataFrame({\n          X.columns[0] : XX,\n          X.columns[1] : YY\n      })\n\n      for j in qual_features:\n        XY[j] = 0\n\n      XY[qual_features[i]] = 1\n\n      p = model.predict(XY)\n      p = p.reshape(xx.shape)\n      \n      \n      # use contour plot to visualize the predictions\n      axarr[i].contourf(xx, yy, p, cmap = \"jet\", alpha = 0.2, vmin = 0, vmax = 2)\n      \n      ix = X[qual_features[i]] == 1\n      # plot the data\n      axarr[i].scatter(x0[ix], x1[ix], c = y[ix], cmap = \"jet\", vmin = 0, vmax = 2)\n      \n      axarr[i].set(xlabel = X.columns[0], \n            ylabel  = X.columns[1], \n            title = qual_features[i])\n      \n      patches = []\n      for color, spec in zip([\"red\", \"green\", \"blue\"], [\"Gentoo\", \"Chinstrap\", \"Adelie\"]):\n        patches.append(Patch(color = color, label = spec))\n\n      plt.legend(title = \"Species\", handles = patches, loc = \"best\")\n      \n      plt.tight_layout()\n\nWe are going to look at both the training data and the testing data, split up by the qualitative factor (the islands).\n\nplot_regions(best_lr, x_train[best_attrs], y_train)\nplot_regions(best_lr, x_test[best_attrs], y_test)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWe can see that the model had no trouble at all with the test data–all the points were clearly within their respective categories on the plot. To continue to test our model against unseen data, we can split up the training data to cross-validate. scikit-learn has a function for this, and it will test our Logistic Regression model against different subsets of the training model.\nCross-validating…\n\nfrom sklearn.model_selection import cross_val_score\ncv_scores_LR = cross_val_score(best_lr, x_train[best_attrs], y_train, cv=5)\nprint(cv_scores_LR.mean())\ncv_scores_LR\n\nOur model did very well on the cross-validation in addition to the training data, with an average score of 99.6%. Another way we can visualize its performance is to create a confusion matrix, which shows us specifically what the model predicted in terms of classification. We will do this with our test data.\nConfusion matrix:\n\nfrom sklearn.metrics import confusion_matrix\n\ny_test_pred = best_lr.predict(x_test[best_attrs])\nC = confusion_matrix(y_test, y_test_pred)\nC\n\narray([[31,  0,  0],\n       [ 0, 11,  0],\n       [ 0,  0, 26]])\n\n\nMore intuitive formatting:\n\nfor i in range(3):\n    for j in range(3):\n        print(f\"There were {C[i,j]} {le.classes_[i]} penguin(s) who were classified as {le.classes_[j]}.\")\n\nThere were 31 Adelie penguin(s) who were classified as Adelie.\nThere were 0 Adelie penguin(s) who were classified as Chinstrap.\nThere were 0 Adelie penguin(s) who were classified as Gentoo.\nThere were 0 Chinstrap penguin(s) who were classified as Adelie.\nThere were 11 Chinstrap penguin(s) who were classified as Chinstrap.\nThere were 0 Chinstrap penguin(s) who were classified as Gentoo.\nThere were 0 Gentoo penguin(s) who were classified as Adelie.\nThere were 0 Gentoo penguin(s) who were classified as Chinstrap.\nThere were 26 Gentoo penguin(s) who were classified as Gentoo.\n\n\nSince the model was 100% correct on the testing data, it is hard to comment on where it could go wrong. However, I predict that false positives for Adelie could occur, since Adelie penguins are found on all three islands. Additionally, the training data included a few penguins who were Chinstraps that were on the border of the Chinstrap and Adelie classifications in the above regions plot.\n\n\nDiscussion\nIn this blog post, we used a Logistic Regression model to classify penguins from the Palmer Penguins dataset. We found that the most important features were the island they were observed on and their culmen dimensions. In general, the model was successful in categorizing the section of the data that we put aside for testing, and it performed well for being trained on only a few features. I am curious if adding more features would improve the accuracy of the model, or if it would introduce overfitting to the model and would become too specific."
  },
  {
    "objectID": "posts/ADS/index.html",
    "href": "posts/ADS/index.html",
    "title": "Design and Impact of Automated Decision Systems",
    "section": "",
    "text": "Abstract\nIn this blog post, we will walk through the process of training a linear regression model, creating a scoring function, and finding an optimal threshold for a scoring and classification problem. The dataset we are working with is one with data about prospective loan borrowers from a bank. It includes various characteristics of each person and the loan they are requesting. We will use this data to determine a threshold and scoring function to determine whether or not, if given the loan, the borrower is likely to default (or, in laymans terms, violate the terms of the loan by not paying/causing the bank to lose money). We will use the scikit-learn library again for this blog post\n\n\nPart A: Grab the Data\nTo begin, let’s import the data:\n\nimport pandas as pd\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\nimport numpy as np\nurl = \"https://raw.githubusercontent.com/PhilChodrow/ml-notes/main/data/credit-risk/train.csv\"\ndf_train = pd.read_csv(url)\n\nWe can take a look at the columns so that we know what attributes we are working with.\n\ndf_train.columns\n\nIndex(['person_age', 'person_income', 'person_home_ownership',\n       'person_emp_length', 'loan_intent', 'loan_grade', 'loan_amnt',\n       'loan_int_rate', 'loan_status', 'loan_percent_income',\n       'cb_person_default_on_file', 'cb_person_cred_hist_length', 'scores'],\n      dtype='object')\n\n\n\n\nPart B: Explore The Data\nNow, we can make a few figures to explore what the data is saying. First, I created a scatterplot to show the relationship between a person’s age and their credit history length. As can be inferred, older people generally have longer credit histories.\n\nfig, ax = plt.subplots(1, 1)\n# cut out the huge outlier--person making 6m/yr--so that we can see patterns more clearly\np1 = sns.scatterplot(df_train[df_train[\"person_age\"] &lt; 100], x = \"cb_person_cred_hist_length\", y = 'person_age', hue = 'cb_person_default_on_file', style = 'cb_person_default_on_file')\n\n\n\n\n\n\n\n\nHowever, I was very interested in the fact that whether or not people defaulted on their loan seemed not to be reliant on age. There are orange x’s in all parts of the plot. Because of this, I wanted to look at the mean age for people who had a history of defaulting and people who didn’t.\n\ndf_train.groupby(\"cb_person_default_on_file\")[\"person_age\"].mean()\n\ncb_person_default_on_file\nN    27.721878\nY    27.793096\nName: person_age, dtype: float64\n\n\nAs you can see, although the average age for people who had defaulted was slightly bigger, they still both had averages of about 27. This was surprising to me because I had previously assumed that people who are older, and therefore have longer credit histories, would be more likely to have defaulted on a loan. I wonder if this is due to financial differences between generations.\nNext, I wanted to look at interest rate based on history of defaulting. I assumed before making the plot that people who had defaulted before would be given a higher interest rate, and I was correct.\n\nbarplot = sns.barplot(df_train, x = \"cb_person_default_on_file\", y = \"loan_int_rate\")\nbarplot.set_title(\"Average loan interest rate separated by previous loan defaults\")\n\nText(0.5, 1.0, 'Average loan interest rate separated by previous loan defaults')\n\n\n\n\n\n\n\n\n\nHere, we can see that the average loan interest rate for those who had not defaulted on a loan previously is about 10%. For those who had, it was about 15%. A 5% increase is quite significant, and it seems like having a clean loan history would significantly benefit someone’s chances at getting a good interest rate.\nNext, I wanted to look at the factors which played into loan intent. To do this, I created a table showing the home ownership counts per loan intent.\n\ndf_train.groupby(\"loan_intent\")[\"person_home_ownership\"].value_counts()\n\nloan_intent        person_home_ownership\nDEBTCONSOLIDATION  RENT                     2260\n                   MORTGAGE                 1841\n                   OWN                        62\n                   OTHER                      15\nEDUCATION          RENT                     2612\n                   MORTGAGE                 2089\n                   OWN                       412\n                   OTHER                      14\nHOMEIMPROVEMENT    MORTGAGE                 1384\n                   RENT                     1252\n                   OWN                       255\n                   OTHER                      11\nMEDICAL            RENT                     2740\n                   MORTGAGE                 1730\n                   OWN                       352\n                   OTHER                      13\nPERSONAL           RENT                     2171\n                   MORTGAGE                 1868\n                   OWN                       354\n                   OTHER                      15\nVENTURE            RENT                     2135\n                   MORTGAGE                 1811\n                   OWN                       648\n                   OTHER                      20\nName: count, dtype: int64\n\n\nWe can see here that there isn’t too much variation, but there are definitely differences that stand out. By far, the most popular type of loan for homeowners is a venture loan, and very few homeowners requested a debt consolidation loan. People with mortgages were spread out pretty evenly across the board, but home improvement had the least mortgagers. By far, home improvement was the least popular type of loan amongst renters. All of these make sense to me for a few reasons. Homeowners gravitated towards venture loans because, in general, they are likely to be more financially stable. Renters did not go for the home improvement loans because they likely don’t have much say in what gets done on the property they are renting. There are so few people in the “other” category that it is hard to pick out trends.\nNext, we are going to prepare the data the same way that we did last time. We will split into x and y, removing the target variables from the training set. We will also get rid of null variables.\n\nfrom sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\nle.fit(df_train[\"loan_status\"])\n\ndef prepare_data(df):\n  df = df.dropna()\n  y = le.transform(df[\"loan_status\"])\n  df = df.drop([\"loan_status\"], axis = 1)\n  df = pd.get_dummies(df)\n  return df, y\n\nx_train, y_train = prepare_data(df_train)\nx_train\n\n\n\n\n\n\n\n\nperson_age\nperson_income\nperson_emp_length\nloan_amnt\nloan_int_rate\nloan_percent_income\ncb_person_cred_hist_length\nperson_home_ownership_MORTGAGE\nperson_home_ownership_OTHER\nperson_home_ownership_OWN\n...\nloan_intent_VENTURE\nloan_grade_A\nloan_grade_B\nloan_grade_C\nloan_grade_D\nloan_grade_E\nloan_grade_F\nloan_grade_G\ncb_person_default_on_file_N\ncb_person_default_on_file_Y\n\n\n\n\n1\n27\n98000\n3.0\n11750\n13.47\n0.12\n6\nFalse\nFalse\nFalse\n...\nFalse\nFalse\nFalse\nTrue\nFalse\nFalse\nFalse\nFalse\nFalse\nTrue\n\n\n2\n22\n36996\n5.0\n10000\n7.51\n0.27\n4\nFalse\nFalse\nFalse\n...\nFalse\nTrue\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nTrue\nFalse\n\n\n3\n24\n26000\n2.0\n1325\n12.87\n0.05\n4\nFalse\nFalse\nFalse\n...\nFalse\nFalse\nFalse\nTrue\nFalse\nFalse\nFalse\nFalse\nTrue\nFalse\n\n\n4\n29\n53004\n2.0\n15000\n9.63\n0.28\n10\nTrue\nFalse\nFalse\n...\nFalse\nTrue\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nTrue\nFalse\n\n\n6\n21\n21700\n2.0\n5500\n14.91\n0.25\n2\nFalse\nFalse\nFalse\n...\nFalse\nFalse\nFalse\nFalse\nTrue\nFalse\nFalse\nFalse\nTrue\nFalse\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n26059\n36\n150000\n8.0\n3000\n7.29\n0.02\n17\nTrue\nFalse\nFalse\n...\nFalse\nTrue\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nTrue\nFalse\n\n\n26060\n23\n48000\n1.0\n4325\n5.42\n0.09\n4\nFalse\nFalse\nFalse\n...\nTrue\nTrue\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nTrue\nFalse\n\n\n26061\n22\n60000\n0.0\n15000\n11.71\n0.25\n4\nFalse\nFalse\nFalse\n...\nFalse\nFalse\nTrue\nFalse\nFalse\nFalse\nFalse\nFalse\nTrue\nFalse\n\n\n26062\n30\n144000\n12.0\n35000\n12.68\n0.24\n8\nTrue\nFalse\nFalse\n...\nFalse\nFalse\nFalse\nTrue\nFalse\nFalse\nFalse\nFalse\nTrue\nFalse\n\n\n26063\n25\n60000\n5.0\n21450\n7.29\n0.36\n4\nFalse\nFalse\nFalse\n...\nFalse\nTrue\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nTrue\nFalse\n\n\n\n\n22907 rows × 26 columns\n\n\n\n\n\nPart C: Build a Model\nNow that the data is properly processed, we can train a logistic regression model. This will follow a similar process to the Penguins blog post, where we loop through all possible combinations of 3 features and add their scores and models to a list.\n\nfrom itertools import combinations\nfrom sklearn.linear_model import LogisticRegression\n\nall_qual_cols = [\"person_home_ownership\", \"loan_intent\", \"cb_person_default_on_file\"]\nall_quant_cols = ['person_age', 'person_income', 'person_emp_length', \"loan_amnt\", \"loan_int_rate\", \"loan_percent_income\", \"cb_person_cred_hist_length\"]\nscores = []\ncombo_array = []\n\n\nfor qual in all_qual_cols:\n  qual_cols = [col for col in x_train.columns if qual in col ]\n  for pair in combinations(all_quant_cols, 2):\n    cols = list(pair) + qual_cols\n    combo_array.append(cols)\n    LR = LogisticRegression()\n    LR.fit(x_train[cols], y_train)\n    new_score = LR.score(x_train[cols], y_train)\n    scores.append((cols, new_score, LR))\n\nNow, we can find the maximum score in the list of results from the model. We can then split up our results into the attributes, the score, and the logistic regression model.\n\nfrom operator import itemgetter\nbest_combo = max(scores, key = itemgetter(1))\nprint(best_combo)\nbest_attrs = best_combo[0]\nbest_score = best_combo[1]\nbest_lr = best_combo[2]\n\n(['person_emp_length', 'loan_percent_income', 'person_home_ownership_MORTGAGE', 'person_home_ownership_OTHER', 'person_home_ownership_OWN', 'person_home_ownership_RENT'], 0.8482559916182826, LogisticRegression())\n\n\nBefore we move on, we should make sure the model doesn’t perform drastically worse on unseen data. Below, we cross-validate our model.\n\nfrom sklearn.model_selection import cross_val_score\ncv_scores_LR = cross_val_score(best_lr, x_train[best_attrs], y_train, cv=5)\nprint(cv_scores_LR.mean())\ncv_scores_LR\n\nWe could have gone through and cross-validated all the possible models, but this score is close enough to our initial score that it is okay to continue.In fact, it performed slightly better on the cross-validation than on the training data. Let’s continue.\nBelow, we can extract the w vector (weights) from our best logistic regression model.\n\nw = pd.Series(best_lr.coef_[0])\nw\n\n0   -0.019247\n1    8.281007\n2   -0.735289\n3   -0.107546\n4   -1.795208\n5    0.265245\ndtype: float64\n\n\n\n\nPart D: Find a Threshold\nNow we begin the process of determining what the most profitable threshold is for the bank. We can start by defining our scoring function, which is just going to be the dot product of the weight vector w.\n\ndef score_function(w, x):\n    return x@w\n\nWe can also plot out these scores by frequency:\n\nx_train['scores'] = score_function(w.values, x_train[best_attrs])\nfig, ax = plt.subplots(1, 1, figsize = (6, 4))\nhist = ax.hist(x_train['scores'], bins = 50, color = \"steelblue\", alpha = 0.6, linewidth = 1, edgecolor = \"black\")\nlabs = ax.set(xlabel = r\"Score\", ylabel = \"Frequency\") \n\n\n\n\n\n\n\n\nMost of the scores fall between 0 and 2. This gives us an idea for where the threshold may fall as well.\nWe can now define the benefit function. We are going to stick with the function given in the assignment, because I do not know much about bank profits!\n\ndef get_benefit(loan_amt, loan_int_rate, default):\n    loan_int_rate = loan_int_rate/100\n    if default == False:\n        cost = loan_amt*(1 + 0.25*loan_int_rate)**10 - loan_amt\n    else:\n        cost = loan_amt*(1 + 0.25*loan_int_rate)**3 - 1.7*loan_amt\n    return cost\n\nNext, I added a column into the dataset for c (profit for someone who doesn’t default) and C (profit for someone who defaults). This helps me to be able to filter more easily in the future! I made sure to apply the function to the whole pandas series for each column, since Pandas can handle vector arithmetic.\n\nx_train['c'] = get_benefit(x_train[\"loan_amnt\"], x_train[\"loan_int_rate\"], False)\nx_train['C'] = get_benefit(x_train[\"loan_amnt\"], x_train[\"loan_int_rate\"], True)\nx_train.head()\n\n\n\n\n\n\n\n\nperson_age\nperson_income\nperson_emp_length\nloan_amnt\nloan_int_rate\nloan_percent_income\ncb_person_cred_hist_length\nperson_home_ownership_MORTGAGE\nperson_home_ownership_OTHER\nperson_home_ownership_OWN\n...\nloan_grade_C\nloan_grade_D\nloan_grade_E\nloan_grade_F\nloan_grade_G\ncb_person_default_on_file_N\ncb_person_default_on_file_Y\nscores\nc\nC\n\n\n\n\n1\n27\n98000\n3.0\n11750\n13.47\n0.12\n6\nFalse\nFalse\nFalse\n...\nTrue\nFalse\nFalse\nFalse\nFalse\nFalse\nTrue\n1.201226\n4613.567568\n-6997.533847\n\n\n2\n22\n36996\n5.0\n10000\n7.51\n0.27\n4\nFalse\nFalse\nFalse\n...\nFalse\nFalse\nFalse\nFalse\nFalse\nTrue\nFalse\n2.404884\n2044.334031\n-6426.108799\n\n\n3\n24\n26000\n2.0\n1325\n12.87\n0.05\n4\nFalse\nFalse\nFalse\n...\nTrue\nFalse\nFalse\nFalse\nFalse\nTrue\nFalse\n0.640802\n493.650464\n-795.445199\n\n\n4\n29\n53004\n2.0\n15000\n9.63\n0.28\n10\nTrue\nFalse\nFalse\n...\nFalse\nFalse\nFalse\nFalse\nFalse\nTrue\nFalse\n1.5449\n4028.690420\n-9390.333437\n\n\n6\n21\n21700\n2.0\n5500\n14.91\n0.25\n2\nFalse\nFalse\nFalse\n...\nFalse\nTrue\nFalse\nFalse\nFalse\nTrue\nFalse\n2.297004\n2430.522429\n-3211.752128\n\n\n\n\n5 rows × 29 columns\n\n\n\nNow for the actual calculations! Below, we loop through 101 possible threshold values and find the benefit for each one. We maintain an array of thresholds and an array of benefits for easy plotting.\n\nbest_benefit = 0\nbest_threshold = 0\nt_arr = []\nbenefits = []\nfig, ax = plt.subplots(1, 1, figsize = (6, 4))\nfor t in np.linspace(0, 3, 101): \n    y_pred = x_train['scores'] &gt;= t\n    tn = ((y_pred == 0) & (y_train == 0)).mean()\n    fn = ((y_pred == 0) & (y_train == 1)).mean()\n    benefit = x_train['c'][x_train['scores'] &gt;= t].sum()*tn - x_train['C'][x_train['scores'] &gt;= t].sum()*fn\n    t_arr.append(t)\n    benefits.append(benefit)\n    if benefit &gt; best_benefit: \n        best_benefit = benefit\n        best_threshold = t\n\nplt.plot(t_arr, benefits)\nplt.plot(best_threshold, best_benefit, marker=\"o\")\nplt.title(f\"Best benefit per person: ${(best_benefit/len(x_train[x_train[\"scores\"] &lt; best_threshold])).round(2)} \\nBest threshold: {best_threshold}\")\nplt.xlabel(\"Threshold score\")\nplt.ylabel(\"Total benefit in dollars\")\n\nText(0, 0.5, 'Total benefit in dollars')\n\n\n\n\n\n\n\n\n\nWe have outputted this plot which shows us the curve of threshold plotted against benefit! We can also see that our best benefit per borrower is $1,868.62, and our optimal threshold is 1.14. Now, let’s test this model and threshold against our testing data. Hopefully, since we did well with the cross-validation, we will do well on the yet unseen data.\n\n\nPart E: Evaluate Your Model from the Bank’s Perspective\n\nurl = \"https://raw.githubusercontent.com/PhilChodrow/ml-notes/main/data/credit-risk/test.csv\"\ndf_test = pd.read_csv(url)\nx_test, y_test = prepare_data(df_test)\nx_test['c'] = get_benefit(x_test[\"loan_amnt\"], x_test[\"loan_int_rate\"], False)\nx_test['C'] = get_benefit(x_test[\"loan_amnt\"], x_test[\"loan_int_rate\"], True)\n\n\nt = best_threshold\n\n# compute the scores\nx_test['scores'] = score_function(w.values, x_test[best_attrs])\npreds = x_test['scores'] &gt;= t\n\n# compute error rates\nFN = ((preds == 0) & (y_test == 1)).mean() \nTN = ((preds == 0) & (y_test == 0)).mean() \n# compute the expected gain\ngain = x_test['c'][x_test['scores'] &gt;= t].sum()*TN  - x_test['c'][x_test['scores'] &gt;= t].sum()*FN\ngain/len(x_test[x_test[\"scores\"] &lt; t])\n\nnp.float64(1361.3320954051185)\n\n\nOur profit per borrower is $1,361.33. Not as much as in our training data, but not bad!\n\n\nPart F: Evaluate Your Model From the Borrower’s Perspective\n\n1. Is it more difficult for people in certain age groups to access credit under your proposed system?\nLet’s look at a plot and find out.\n\nplot = sns.scatterplot(x_train[x_train[\"person_age\"] &lt; 100], x = \"person_age\", y = \"scores\")\nplot.set_title(\"Scores against age for prospective borrowers\")\n\nText(0.5, 1.0, 'Scores against age for prospective borrowers')\n\n\n\n\n\n\n\n\n\nIt doesn’t look like there is much correlation between score and age.\n\n\nIs it more difficult for people to get loans in order to pay for medical expenses? How does this compare with the actual rate of default in that group? What about people seeking loans for business ventures or education?\nLet’s check out the data:\n\ndf_train[\"scores\"] = x_train[\"scores\"]\ndf_train.groupby(\"loan_intent\")[\"scores\"].max()\n\nloan_intent\nDEBTCONSOLIDATION     6.14476\nEDUCATION            6.449154\nHOMEIMPROVEMENT       6.06195\nMEDICAL              5.965717\nPERSONAL             6.137947\nVENTURE               5.89633\nName: scores, dtype: object\n\n\nSo the maximum score for medical is lower than almost all the other maximum scores. However, this may not reflect the average score given to medical borrowers.\n\ndf_train.groupby(\"loan_intent\")[\"scores\"].mean()\n\nloan_intent\nDEBTCONSOLIDATION    1.114447\nEDUCATION             1.00498\nHOMEIMPROVEMENT      0.873225\nMEDICAL              1.100077\nPERSONAL             0.969918\nVENTURE              0.900046\nName: scores, dtype: object\n\n\nHere, we can see that the average score for a medical loan request is actually higher than many of the other categories. In general, the Venture category has a low score for both the max score and the mean score. Debt consolidation tends to score hgih, as does education. Medical flips from the high end (mean) to the low end (max). We can also look at the count of each that got a loan, as opposed to the true default values.\n\ndf_train[df_train[\"scores\"] &gt;= best_threshold].groupby(\"loan_intent\").size() - df_train[df_train[\"scores\"] &gt;= best_threshold][df_train[\"loan_status\"] == 0].groupby(\"loan_intent\").size()\n\n/var/folders/sy/9tmrg3gx65vf4qjw8jl8ytsc0000gn/T/ipykernel_82223/2869003493.py:1: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n  df_train[df_train[\"scores\"] &gt;= best_threshold].groupby(\"loan_intent\").size() - df_train[df_train[\"scores\"] &gt;= best_threshold][df_train[\"loan_status\"] == 0].groupby(\"loan_intent\").size()\n\n\nloan_intent\nDEBTCONSOLIDATION    648\nEDUCATION            574\nHOMEIMPROVEMENT      424\nMEDICAL              718\nPERSONAL             534\nVENTURE              468\ndtype: int64\n\n\nHere, we calculated the number of people in each loan intent group that were above the threshold and defaulted. Overall, it seems like the error rate among groups was pretty equal when you consider the size of the groups.\n\n\nHow does a person’s income level impact the ease with which they can access credit under your decision system?\n\nsns.scatterplot(x = x_train[x_train[\"person_income\"] &lt; 2000000][\"person_income\"], y = x_train[\"scores\"])\n\n\n\n\n\n\n\n\nOverall, it seems like lower-income people are more likely to receive a higher score. This is interesting to me because I would assume those who are higher income would be more likely to pay off their loans. However, maybe interest rates are higher among lower-income people in this dataset. Also, it could have something to do with the reasons people are requesting loans.\n\n\n\nPart G: Write and Reflect\n\nConsidering that people seeking loans for medical expense have high rates of default, is it fair that it is more difficult for them to obtain access to credit?\nI think this depends on whether you are thinking from a utilitarian or ethical view of fairness. I also think that fairness is not necessary always ethical in the ways people use it. I believe that it is unfair that people who need help cannot access it, and I think it is sad that profits are often prioritized over people. However, I can see how someone would argue that while it is unethical to deny someone a medical loan, it may still be fair. Basing loans off of likelihood of default is an objective way of making the decision, and I think some people see objectivity as fairness.\n\n\n\nDiscussion"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Elli Sterling’s CSCI 0451 Blog",
    "section": "",
    "text": "Design and Impact of Automated Decision Systems\n\n\n\n\n\nDesigning an algorithm to decide whether or not loan applicants should receive loans.\n\n\n\n\n\nFeb 27, 2025\n\n\nEleanor Sterling\n\n\n\n\n\n\n\n\n\n\n\n\nClassifying Palmer Penguins\n\n\n\n\n\nClassifying penguins by species based on the Palmer Penguins dataset\n\n\n\n\n\nFeb 12, 2025\n\n\nEleanor Sterling\n\n\n\n\n\n\nNo matching items"
  }
]