<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.40">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Eleanor Sterling">
<meta name="dcterms.date" content="2025-05-12">

<title>Attempting to Predict ENSO Phases – My Awesome CSCI 0451 Blog</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-549806ee2085284f45b00abea8c6df48.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap-6de787833effe4777a6777a5e05fb578.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<style>

      .quarto-title-block .quarto-title-banner h1,
      .quarto-title-block .quarto-title-banner h2,
      .quarto-title-block .quarto-title-banner h3,
      .quarto-title-block .quarto-title-banner h4,
      .quarto-title-block .quarto-title-banner h5,
      .quarto-title-block .quarto-title-banner h6
      {
        color: white;
      }

      .quarto-title-block .quarto-title-banner {
        color: white;
background-image: url(../../img/landscape.png);
background-size: cover;
      }
</style>


<link rel="stylesheet" href="../../styles.css">
</head>

<body class="nav-fixed fullcontent">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top quarto-banner">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">My Awesome CSCI 0451 Blog</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../about.html"> 
<span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/"> <i class="bi bi-github" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://twitter.com"> <i class="bi bi-twitter" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">Attempting to Predict ENSO Phases</h1>
                      </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>Eleanor Sterling </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">May 12, 2025</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">





<section id="abstract" class="level3">
<h3 class="anchored" data-anchor-id="abstract">Abstract</h3>
<p>Modeling the El Niño Southern Oscillation is a problem that has plagued climate scientists due to the lack of observed data to train models on. This blog post will describe how I attempted to train a Logistic Regression model on observed and reconstructed sea surface temperature data in order to predict ENSO phases. The data processing for this project was what took the most time, and had I been more proficient with using spatiotemporal data, I may have had more time to implement more complex algorithms and find more success. I used sea surface temperature (SST) data from the Pacific Ocean, clipped to exclude extra cold areas and other oceans. I then split that data into regions, which I used as features. In the end, my Logistic Regression models using both Gradient Descent and Adam optimizers ended up achieving 50-60% accuracy on training data. I then input my feature matrix and target vector into five scikit-learn models, which found slightly more success. I then posited on future steps and modeling techniques that could make this project successful in the future.</p>
<p>The source code for this project is located <a href="https://github.com/ellisterling/enso-predictor">here</a>.</p>
</section>
<section id="introduction" class="level3">
<h3 class="anchored" data-anchor-id="introduction">Introduction</h3>
<p>The El Niño Southern Oscillation (ENSO) is a climate circulation pattern resulting from temperature dynamics in the Equatorial Pacific Ocean. Colder temperatures along the South American coast indicate a La Niña year, and can cause increased rainfall in areas like India with a pronounced monsoon season. Figure 1 illustrates what the sea surface temperatures can look like in the Pacific when a La Niña phase is happening.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="index_files/figure-html/6cd32a42-1-ENSO.png" class="img-fluid figure-img"></p>
<figcaption><strong>Figure 1:</strong> an example of plotted SST from a La Niña phase (September 1, 2008).</figcaption>
</figure>
</div>
<p>ENSO is a phenomenon that is interconnected with the entire earth system. The figure below from <span class="citation" data-cites="Anderson_Lucas_2008">Anderson and Lucas (<a href="#ref-Anderson_Lucas_2008" role="doc-biblioref">2008</a>)</span> illustrates some of the Earth System processes that affect and are affected by ENSO. Specifically, it illustrates how wind and precipitation are broadly affected by (and how they affect) the SST in different parts of the Pacific.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="index_files/figure-html/6cd32a42-2-image.png" class="img-fluid figure-img"></p>
<figcaption><strong>Figure 2:</strong> A conceptual diagram of ENSO and some of its interconnectivity with atmospheric systems sourced from <span class="citation" data-cites="Anderson_Lucas_2008">Anderson and Lucas (<a href="#ref-Anderson_Lucas_2008" role="doc-biblioref">2008</a>)</span>. Figure (a) shows La Niña. Figure (b) shows El Niño.</figcaption>
</figure>
</div>
<p>In doing this project, I wanted to see if simple Logistic Regression could classify future El Nino stages 6 months in advance based on current sea surface temperature variables. Others have implemented machine learning algorithms to solve this problem with climate model output integration and/or increased features in terms of factors indicating ENSO (SST, sea surface height, precipitation, etc.). Specifically, it is difficult to create a model that doesn’t include any climate modeling because satellite monitoring of Earth only started in the late 1900s (<span class="citation" data-cites="Chen_Gilani_Harlim_2021">Chen, Gilani, and Harlim (<a href="#ref-Chen_Gilani_Harlim_2021" role="doc-biblioref">2021</a>)</span>), so there is an extremely limited range of data available to train models on. Most models, even if they don’t use predictive models to directly predict ENSO conditions, will use reconstructed climate from a Global Climate Model in order to expand their dataset. <span class="citation" data-cites="Chen_Gilani_Harlim_2021">Chen, Gilani, and Harlim (<a href="#ref-Chen_Gilani_Harlim_2021" role="doc-biblioref">2021</a>)</span> implemented a Bayesian model that avoided the use of modeling that was able to achieve better accuracy than some models that are integrated with climate models. Notably, this model included many more features than we will use in this implementation. <span class="citation" data-cites="Hernández_Mesa_Lall_2020">Hernández, Mesa, and Lall (<a href="#ref-Hernández_Mesa_Lall_2020" role="doc-biblioref">2020</a>)</span> were also able to successfully predict ENSO using a non-homogenous Hidden Markov Model. After learning about HMMs in AI, this implementation makes a lot of sense based on how climate proxies are also, in a way, indicators of hidden states. In this blog post, I will describe how I attempted to implement a Logistic Regression model able to predict ENSO stages with reduced features from other implementations.</p>
</section>
<section id="values-statement" class="level3">
<h3 class="anchored" data-anchor-id="values-statement">Values Statement</h3>
<p>The potential users of this project, had it been more successful, would have been policymakers and communities who are generally more affected by El Nino/La Nina conditions. Additionally, scientists could use this model and improve it using climate modeling. Other than these users, people who could be affected by this project include people who live in areas that are heavily impacted by these events–a wrong prediction could be hazardous if communities prepare in one way and are unprepared for another. I think these are the same people who would benefit from this technology. Additionally, it would in theory be less computationally expensive than implementing a climate model and using those results to inform predictions, so it would have been helpful to scientists and others implementing climate prediction models had it worked. People who could be harmed include the previously mentioned groups since a wrong prediction could be detrimental to communities preparing for one outcome and getting another.</p>
<p>I wanted to work on this problem because, after reading about ENSO and learning about it in classes, I was interested to see if sea surface temperature (SST) alone (initially, along with precipitation) could predict future stages. I had learned a lot about climate modeling in some of my Earth and Climate Science classes, and wanted to see if I could implement algorithms from this class to predict ENSO events. I also just wanted to combine my ECSC knowledge with a project for CS!</p>
<p>I do not think the world will be a necessarily more or less equitable, just, joyful, or sustainable place because of what I implented, mainly because it was not very successful in terms of what I was able to produce. I think that the main effect this technology will have will be on me, simply because now I know firsthand how it is very difficult to predict weather patterns, even well-defined ones.</p>
</section>
<section id="materials-and-methods" class="level3">
<h3 class="anchored" data-anchor-id="materials-and-methods">Materials and Methods</h3>
<section id="data" class="level4">
<h4 class="anchored" data-anchor-id="data">Data</h4>
<p>For the SST data, I used the Japan Meteorological Associaation’s COBE-SST 2 dataset (<span class="citation" data-cites="NOAAsst">Japanese Meteorological Association (<a href="#ref-NOAAsst" role="doc-biblioref">2025</a>)</span>). COBE-SST 2 and Sea Ice data was provided by the NOAA PSL, Boulder, Colorado, USA, from their website at <a href="https://psl.noaa.gov">https://psl.noaa.gov</a>. This dataset goes back to 1850, but I had to subset this data to only include years after 1950. This was necessary in order to match the range of the feature matrix with the data I used for the target vector. Much of this data has been filled in/reconstructed in order to account for the lack of data before the late 1900s. The target data was derived from the Oceanic Nino Index (ONI) dataset, sourced from the <span class="citation" data-cites="ONI">National Weather Service Climate Prediction Center (<a href="#ref-ONI" role="doc-biblioref">2013</a>)</span>. The ONI goes back to 1950, and represents an ocean-wide anomaly (or change from the normal). An ONI of &lt; -0.5 indicates a La Nina phase, whereas an ONI of &gt; 0.5 indicates an El Nino phase. Each row in my dataset represents the yearly SST average. The columns of my feature matrix are all regions of the ocean. There is no precipitation data included in this dataset, which I will explain in the following section.</p>
</section>
<section id="approach" class="level4">
<h4 class="anchored" data-anchor-id="approach">Approach</h4>
<p>The first thing I did in order to process this data was to clip it to only include data from the Pacific Ocean. I also clipped out the ocean closest to the North and South Poles because their temperature is always hovering around 32 degrees Fahrenheit regardless of the ENSO phase, and ENSO is mainly affected by just the Equatorial Pacific.</p>
<p>I went through this data and turned it into first ternary data and then binary. This was because I did not have time to implement a multinomial optimizer. In the end, I classified years where the ONI was &lt; 0 as La Nina, and years where the ONI was &gt; 0 as El Nino. This simplification certainly could have caused issues, but when I ran an sklearn model on each of them, I found that the target vector with three classes actually resulted in worse accuracy (probably because I didn’t have enough data points). I used all the regions/features as predictors, which also could have affected accuracy (again, because of the small amount of data points I had.)</p>
<p>In the time given to work on the project I couldn’t figure out how to deal with both spatial and temporal data without making the spatial aspect the features. With this structure of the feature matrix, I couldn’t figure out how to add precipitation without changing the whole structure of the data. This means that the only climate data I could use as a feature was SST. I came into this project also wanting to include precipitation, but did not end up getting there with this project.</p>
<p>When I realized how much trouble the data was giving me, I pivoted to just trying to classify current ENSO states, which proved harder than I expected. To do this I used Logistic Regression with Gradient Descent Optimizer and Adam Optimizer. I wasn’t able to get them to reach good accuracy on the training data, so I then pivoted to testing other sklearn models. I created a 60/40 train-test split before running the sklearn implementations of Logistic Regression with LBFGS, liblinear, and Stochastic Gradient descent optimizers. I then ran the sklearn implementations of Naive Bayes and Random Forest classifiers. I evaluated their performance by their accuracy and whether or not they just predicted all 1s or all 0s.</p>
</section>
</section>
<section id="results" class="level3">
<h3 class="anchored" data-anchor-id="results">Results</h3>
<p>When I ran the models that I implemented myself, I couldn’t get them to predict anything other than all 1s or all 0s. Depending on the train-test split, sometimes Adam would predict mostly 1s and a few 0s or mostly 0s and a few 1s, but it didn’t affect the accuracy. The accuracy on the training data for both hovered around 50%, which makes sense when you consider how they were only predicting one class for the whole dataset. The loss plots for both of them looked odd, and although Gradient Descent appeared to converge, it converged to a low accuracy.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="index_files/figure-html/c801620b-1-image.png" class="img-fluid figure-img"></p>
<figcaption><strong>Figure #:</strong> Loss over iterations for Adam and Gradient Descent optimizers for Logistic Regression.</figcaption>
</figure>
</div>
<p>After wrestling with the handmade models, trying to get them to work and failing, I decided to check the sklearn implementations of a few different models to see how they fared. Below are the results of the end accuracy for five different models for one of the runs. Most of the models hover around 50% accuracy, just as our handmade models did. Logistic Regression actually performed the best and most consistently, generally producing accuracies of about 70%-80% with the liblinear and LBFGS optimizers. Occasionally, Naive Bayes would also perform well, but it was more unreliable than the LR implementations.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="index_files/figure-html/81591e0e-1-image.png" class="img-fluid figure-img"></p>
<figcaption><strong>Figure #:</strong> Accuracty of five models from the scikit-learn library.</figcaption>
</figure>
</div>
<p>I also tested the sklearn models on my data with multinomial classifiers (La Niña, El Niño, or Neutral phases). Interestingly, many of the models generally performed worse when trying to classify the data this way.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="index_files/figure-html/d2ec57a0-1-image.png" class="img-fluid figure-img"></p>
<figcaption><strong>Figure #:</strong> Model accuracy plotted for multinomial and binary classification. The accuracy for the Binary classification is slightly different than in Figure # because it came from a different model run with different train-test splits/different starting weight vectors.</figcaption>
</figure>
</div>
<p>Multinomial classification performed slightly better for the Bayes model and the SGD model on this run, but it is very close for the Bayes. In many other runs, Binary performed better for Bayes as well, and the only model that consistently performed better with the multinomial data was Stochastic Gradient Descent (SGD). This model also consistently performed the worst of all the models, regardless of target vector.</p>
</section>
<section id="discussion" class="level3">
<h3 class="anchored" data-anchor-id="discussion">Discussion</h3>
<p>The results of this project clearly do not show much success–I wasn’t able to achieve any more than 55% accuracy with the algorithms I implemented, and even most of scikit-learn’s algorithms didn’t have great accuracy. liblinear and LBFGS were two Logistic Regression optimizers that performed very well (70%-80% accuracy), so if I had more time on this project, I would have attempted to implement them. However, the greater question is whether or not this approach was the right one at all. First of all, I used binary classification, which is not accurate to the actual phases, and necessarily classifies neutral phases as El Niño or La Niña. As we saw from the scikit-learn models, implementing multinomial classification probably would have harmed my models’ accuracy. This likely occurred because I didn’t have enough data points. Also, many previous studies attempting to implement machine learning to predict ENSO have done so by combining with predictive climate model output. When I started this project, I was curious if it would be possible to implement a predictor without doing so. Although people have implemented machine learning algorithms that predict ENSO without using future climate model predictions, these algorithms all used many more features than I included. Additionally, I went into this with very little experience doing machine learning with data that was both spatial and temporal, and so my solution to this problem (to assign regions within the Equatorial Pacific and use those regions as features) was maybe not the best approach either. Given that researchers such as <span class="citation" data-cites="Chen_Gilani_Harlim_2021">Chen, Gilani, and Harlim (<a href="#ref-Chen_Gilani_Harlim_2021" role="doc-biblioref">2021</a>)</span>, <span class="citation" data-cites="Hernández_Mesa_Lall_2020">Hernández, Mesa, and Lall (<a href="#ref-Hernández_Mesa_Lall_2020" role="doc-biblioref">2020</a>)</span>, and <span class="citation" data-cites="Pal_Maity_Ratnam_Nonaka_Behera_2020">Pal et al. (<a href="#ref-Pal_Maity_Ratnam_Nonaka_Behera_2020" role="doc-biblioref">2020</a>)</span> have been able to achieve very good accuracy with their models, and experts in the field can predict stages without the help of machine learning, I am certain that the general idea of this project has a future in the machine learning and climate science communities. However, the way I went about implementing my algorithm was not the optimal one. Future implementations should either integrate with climate models or include more features to account for the interconnectedness of the climate system. As the climate warms, integration with models may become more necessary because our understanding of ENSO could shift with a warming climate and more intense phases.</p>
</section>
<section id="group-contribution" class="level3">
<h3 class="anchored" data-anchor-id="group-contribution">Group Contribution</h3>
<p>Because I was working on this project alone, I worked on all parts of the source code and completed all the work related to this project.</p>
</section>
<section id="personal-reflection" class="level3">
<h3 class="anchored" data-anchor-id="personal-reflection">Personal Reflection</h3>
<p>One thing I learned from the process of creating this project is that things that seem simple can often be quite complicated. I really struggled with the data wrangling–since I had experience using other peoples’ climate models, I assumed that working with spatial data would be fine. However, the combination of spatial and temporal data ended up throwing me for a loop. I think the solution I came up with was reasonable, but it was definitely a “make-do” kind of situation. Additionally, I learned a lot from reading papers about ENSO and how connected it is to the entire Earth system. I had an idea of this from previous classes, but it was cool to be able to read scientific papers on it and see how predictions are made.</p>
<p>Unfortunately, I did not meet my goal for this project. I thought that a good backup would be to try and classify current ENSO stages instead of predicting them, but I also did not obtain good accuracy for this. However, I do think that I learned a lot about why what I was going to attempt wouldn’t work, and why climate modeling is likely needed in order to confidently predict future atmospheric circulation. Additionally, when I undertook this project, I was aiming for accuracy of 50% or more–which I did obtain. Unfortunately, that accuracy is not enough to be useful in its function as a predictor.</p>
<p>I had to do a lot of pivoting in this project, and I think that in the future, I will take the flexibility that I gained here and put it to use. It was good practice in scaling down my expectations in the moment and working with what I had. This will be useful in all aspects of my future life, including personal, professional, and any academic work I may continue doing in the future.</p>



</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" role="doc-bibliography" id="quarto-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list">
<div id="ref-Anderson_Lucas_2008" class="csl-entry" role="listitem">
Anderson, T. R., and M. I. Lucas. 2008. <span>“Upwelling Ecosystems.”</span> In <em>Encyclopedia of Ecology (Second Edition)</em>, edited by Brian Fath, 700–710. Oxford: Elsevier. <a href="https://doi.org/10.1016/B978-0-444-63768-0.00363-2">https://doi.org/10.1016/B978-0-444-63768-0.00363-2</a>.
</div>
<div id="ref-Chen_Gilani_Harlim_2021" class="csl-entry" role="listitem">
Chen, Nan, Faheem Gilani, and John Harlim. 2021. <span>“A Bayesian Machine Learning Algorithm for Predicting ENSO Using Short Observational Time Series.”</span> <em>Geophysical Research Letters</em> 48 (17): e2021GL093704. <a href="https://doi.org/10.1029/2021GL093704">https://doi.org/10.1029/2021GL093704</a>.
</div>
<div id="ref-Hernández_Mesa_Lall_2020" class="csl-entry" role="listitem">
Hernández, Julián David Rojo, Óscar José Mesa, and Upmanu Lall. 2020. <span>“ENSO Dynamics, Trends, and Prediction Using Machine Learning,”</span> October. <a href="https://doi.org/10.1175/WAF-D-20-0031.1">https://doi.org/10.1175/WAF-D-20-0031.1</a>.
</div>
<div id="ref-NOAAsst" class="csl-entry" role="listitem">
Japanese Meteorological Association. 2025. <span>“COBE-SST 2 and Sea Ice.”</span> Dataset; <span>National Oceanic and Atmospheric Administration</span>. <a href="https://psl.noaa.gov/data/gridded/data.cobe2.html">https://psl.noaa.gov/data/gridded/data.cobe2.html</a>.
</div>
<div id="ref-ONI" class="csl-entry" role="listitem">
National Weather Service Climate Prediction Center. 2013. <span>“Description of Changes to the Oceanic Nino Index (ONI).”</span> Dataset; <span>National Oceanic and Atmospheric Administration</span>. <a href="https://origin.cpc.ncep.noaa.gov/products/analysis_monitoring/ensostuff/ONI_change.shtml">https://origin.cpc.ncep.noaa.gov/products/analysis_monitoring/ensostuff/ONI_change.shtml</a>.
</div>
<div id="ref-Pal_Maity_Ratnam_Nonaka_Behera_2020" class="csl-entry" role="listitem">
Pal, Manali, Rajib Maity, J. V. Ratnam, Masami Nonaka, and Swadhin K. Behera. 2020. <span>“Long-Lead Prediction of ENSO Modoki Index Using Machine Learning Algorithms.”</span> <em>Scientific Reports</em> 10 (1): 365. <a href="https://doi.org/10.1038/s41598-019-57183-3">https://doi.org/10.1038/s41598-019-57183-3</a>.
</div>
</div></section></div></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>